{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating tensor and manipulating them"
      ],
      "metadata": {
        "id": "Ybc0eOsOHVFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating tensors and basic properties\n",
        "\n",
        "**Create Tensors**\n",
        "* `torch.tensor()`: create random tensor with given structure and numbers\n",
        "* `torch.rand()`: create random tensor with given dimensions\n",
        "* `torch.zeros()`: create a tensor filled with zeros\n",
        "* `torch.ones()`: create a tensor filled with ones\n",
        "* `torch.arange()`: create a range (similar to function `range` but output is a tensor)\n",
        "\n",
        "**Attributes**\n",
        "* `.dtype`: data type\n",
        "* `.type()`: assign a new type\n",
        "* `.shape`: shape of the tensor\n",
        "* `.device`: on which device the tensor lives\n",
        "\n",
        "**Misc**\n",
        "* `torch.manual_seed()`: to reset the seed\n"
      ],
      "metadata": {
        "id": "ueRF9VNEEKsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensor\n",
        "\n",
        "print(torch.tensor[7, 7])\n",
        "print(torch.tensor[1, 2], [3, 4]])\n",
        "print(torch.tensor[[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n"
      ],
      "metadata": {
        "id": "up2jZKiLEhTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulating tensors\n",
        "\n",
        "* `.reshape()`: change the shape of the tensor\n",
        "* `.view()`: change the view: creates a new view, the 2 tensors data are the same, changing one tensor changes the other as well but the shape of the view will be different\n",
        "* `.stack()`: stack tensors of compatible dimensions\n",
        "* `.permute()`: change order of dimensions, *useful to move colour channel first to last and viceversa*\n",
        "* `.squeeze()` and `.unsqueeze()`: remove or add dimensions to a tensor\n"
      ],
      "metadata": {
        "id": "Ys3D1zm0EKou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch `nn.Module()`\n",
        "\n",
        "* `nn.Module()`: class to define models: when subclassing they need a self and a forward method inside\n",
        "* `nn.Parameters()`: to manually define parameters\n",
        "* loss functions:\n",
        "  * `nn.L1Loss`: MSE loss for fitting linear models\n",
        "  * `nn.CrossEntropyLoss`: cross entropy for multi-class classification\n",
        "  * `nn.BCEWithLogitsLoss()`: for binary classification, includes sigmoid activation function. Outputs logits, use `torch.sigmoid()` to transform into predictions/probabilities\n",
        "* `torch.optim.SGD()`: Stochastic Gradient Descent algorithm\n",
        "\n",
        "**`nn.Module` possible transformations**\n",
        "* `nn.Sequential()`: to put together several transformations\n",
        "* `nn.Linear()`: for linear transformation (e.g. simple linear regression)\n",
        "* `nn.Conv2d()`: convolution step\n",
        "* `nn.ReLU()`: rectified linear activation function $max(0,x)$\n",
        "* `nn.Flatten()`: transform a multi-dimensional tensor in a vector\n",
        "* `nn.MaxPool2d()`: take maximum over a square of pixels and reduce dimensions\n",
        "* ``:\n",
        "* ``:\n",
        "\n",
        "**Methods and Attributes for a model:**\n",
        "* `a_model.state_dict()`: to get dictionary of parameters\n",
        "* `a_model.eval()`, `a_model.train()`: eval and train status\n",
        "* `with torch.inference()`: to turn off gradients, necessary when forecasting or calculating test performance\n"
      ],
      "metadata": {
        "id": "C_iDUIwIEKmX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TinyVGG architecture model\n",
        "\n",
        "```python\n",
        "class TinyVGGArchitecture(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture replicating TinyVGG\n",
        "  from CNN explainer website.\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int, # number of hidden units, it's not the size of each concoluted picture\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    # architecure: multiple blocks\n",
        "    # convolutional blocks: multiple layers\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, # convolutional 2 dimensional\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1), # we set these values in NN\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, # convolutional 2 dimensional\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2) # by default same as kernel size\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    # last block needs to output a classifier\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(x.shape) # to help get the right size in the Linear layer\n",
        "    x = self.conv_block_2(x)\n",
        "    # print(x.shape)\n",
        "    x = self.classifier(x)\n",
        "    # print(x.shape)\n",
        "    return x\n",
        "```"
      ],
      "metadata": {
        "id": "JcA3RphHyPFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting a model\n",
        "\n",
        "1. Set up number of epochs (iteration)\n",
        "1. Set up epochs loop\n",
        "1. Set up loop through batches in a DataLoader\n",
        "1. `a_model.train()`: Get model in train mode\n",
        "1. `a_model(X_data)`: Do a forward pass\n",
        "1. `loss_fn(y_pred, y_test)`: Calculate the train loss\n",
        "  * Maybe necessary to transform the output: e.g. from logit to probability\n",
        "1. `optimizer.zero_grad()`: Reset the optimizer\n",
        "1. `loss_fn.backward()`: Perform loss propagation backward\n",
        "1. `optimizer.setp()`: Perform optimizer step\n",
        "\n",
        "```python\n",
        "# set the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# set number of epochs\n",
        "epochs = 3\n",
        "\n",
        "# create training and test loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n---------\")\n",
        "  ### Training\n",
        "  train_loss = 0 # cumulates loss per batch\n",
        "  # Loop through batches\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    # forward pass\n",
        "    y_pred = model_0(X)\n",
        "    # loss\n",
        "    loss =loss_fn(y_pred, y)\n",
        "    train_loss += loss # accumulates the train loss\n",
        "    # optimizer reset\n",
        "    optimizer.zero_grad()\n",
        "    # loss backward\n",
        "    loss.backward()\n",
        "    # optimizer step: updating model parameters once per BATCH\n",
        "    optimizer.step()\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
        "\n",
        "  # back to epoch loop\n",
        "  # divide loss by length dataloader\n",
        "  train_loss /= len(train_dataloader)\n",
        "\n",
        "  # testing loop\n",
        "  model_0.eval()\n",
        "  test_loss, test_acc = 0, 0\n",
        "  with torch.inference_mode():\n",
        "    for X_test, y_test in test_dataloader:\n",
        "      # forward pass\n",
        "      test_pred = model_0(X_test)\n",
        "      # loss\n",
        "      test_loss += loss_fn(test_pred, y_test)\n",
        "      # accuracy\n",
        "      test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
        "    # calculate the test loss average per batch\n",
        "    test_loss /= len(test_dataloader)\n",
        "    # accuracy average\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  print(f\"\\nTrain loss: {train_loss:.4f} | Train acc: {test_acc:.2f}%\\nTest loss: {test_loss:.4f} | Test acc: {test_acc:.2f}%\")\n",
        "```"
      ],
      "metadata": {
        "id": "V4vB8PBxp9m4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and creating datasets"
      ],
      "metadata": {
        "id": "xqxWthmwtkX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader\n",
        "\n",
        "`from torch.utils.data import DataLoader` to create batches of data as it's computationally impossible to use all images at the same time. Good batch size are powers of 2, like 32 or 64.\n",
        "* use `next(iter(aDataLoader))` to access one batch of data/images"
      ],
      "metadata": {
        "id": "unj4uTJPtoNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating models"
      ],
      "metadata": {
        "id": "GvKja0BNy83Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torchvision\n",
        "\n",
        "* `import datasets`: contains datasets\n",
        "* `import transform`: contains transformation to adapt images to correct format/size or to augment data"
      ],
      "metadata": {
        "id": "fxvn_2TGtFvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torchmetrics\n",
        "\n",
        "```python\n",
        "try:\n",
        "  import torchmetrics\n",
        "except:\n",
        "  !pip install -q torchmetrics\n",
        "  import torchmetrics\n",
        "```\n",
        "\n",
        "Contains functions to help evaluate models\n",
        "* `Accuracy()`"
      ],
      "metadata": {
        "id": "R7IIIgVfuXXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix\n",
        "\n",
        "```python\n",
        "from torchmetrics import ConfusionMatrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Tvh3aBVDwcgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `sklearn` useful functions\n",
        "\n",
        "* `from sklearn.datasets import make_circles, moons, make_blobs`: to create artifical datasets\n",
        "* `from sklearn.model_selection import train_test_split`: to split dataset into train and test datasets"
      ],
      "metadata": {
        "id": "kvkuJv_srVRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc\n",
        "\n",
        "* `from tqdm,auto import tqdm`: to have a progress bar when running a loop\n",
        "* `from timeit import default_timer as timer`: to get system time"
      ],
      "metadata": {
        "id": "kNHZbqcYuseI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymBfdcpZrU9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}